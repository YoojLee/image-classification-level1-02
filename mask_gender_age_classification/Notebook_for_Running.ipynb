{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "os.getcwd()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/opt/ml/input/data/train/resnet18_final'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "\n",
    "seed_everything(2021)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data_dir = '/opt/ml/input/data/train'\n",
    "img_dir = f'{data_dir}/images'\n",
    "df_path = f'{data_dir}/train.csv'\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "import Dataset\n",
    "# normalize를 위한 대략적인 RGB 값 평균 \n",
    "mean, std = (0.5, 0.5, 0.5), (0.2, 0.2, 0.2) \n",
    "\n",
    "transform = Dataset.get_transforms(mean=mean, std=std)\n",
    "\n",
    "dataset = Dataset.MaskBaseDataset(\n",
    "    img_dir = img_dir\n",
    ")\n",
    "\n",
    "# train dataset과 validation dataset을 8:2 비율로 나눕니다.\n",
    "n_val = int(len(dataset) * 0.2)\n",
    "n_train = len(dataset) - n_val\n",
    "train_dataset, val_dataset = data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# 각 dataset에 augmentation 함수를 설정합니다.\n",
    "train_dataset.dataset.set_transform(transform['train'])\n",
    "val_dataset.dataset.set_transform(transform['val'])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data loader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=2,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_loader = data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=2,\n",
    "    shuffle=False\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import Pretrained_Model\n",
    "model = Pretrained_Model.pretrainedModel().to(device)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# optimizer = optim.SGD(model.parameters(), lr=0.01,\n",
    "#                      momentum=0.9, weight_decay = 0.0005)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size= 10, gamma=0.1) #학습률 점차 감소"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import Loss\n",
    "#criterion = Loss.FocalLoss()\n",
    "criterion = F.cross_entropy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer  = SummaryWriter('./exp/18_class_last' )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import Train_Process\n",
    "EPOCHS= 30\n",
    "for epoch in tqdm(range(1, EPOCHS+1)):\n",
    "    train_loss, train_acc, f1 = Train_Process.train(\n",
    "                                    model = model,\n",
    "                                    train_loader= train_loader, \n",
    "                                    loss = criterion,\n",
    "                                    optimizer = optimizer, \n",
    "                                    writer = writer,\n",
    "                                    device = device,\n",
    " )\n",
    "    #scheduler.step()\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('acc/train', train_acc, epoch)\n",
    "    writer.add_scalar('F1_score/train', f1, epoch)\n",
    "    print(f'[{epoch}] train loss : {train_loss}, train acc : {train_acc}, train f1 : {f1:.4f}')\n",
    "    \n",
    "    valid_loss, valid_acc, val_f1 = Train_Process.evaluate(\n",
    "                                            model = model, \n",
    "                                            val_loader = val_loader, \n",
    "                                            loss = criterion,\n",
    "                                            writer = writer,\n",
    "                                            device = device,\n",
    "                                            )\n",
    "    writer.add_scalar('Loss/valid', valid_loss, epoch)\n",
    "    writer.add_scalar('acc/valid', valid_acc, epoch)\n",
    "    writer.add_scalar('F1_score/valid',  val_f1 , epoch)\n",
    "\n",
    "    print(f'[{epoch}] valid loss : {valid_loss}, valid acc : {valid_acc}, valid f1 : {val_f1:.4f}')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8ba702ec3ce42e4b070fe8b6e4341a1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished Training\n",
      "[1] train loss : 2.4154041966539808e-06, train acc : 0.19406709176601053, train f1 : 0.0295\n",
      "[1] valid loss : 0.5872509936761552, valid acc : 85.94399778209038, valid f1 : 0.0235\n",
      "Finished Training\n",
      "[2] train loss : 1.5482597518712282e-05, train acc : 0.17327418907679512, train f1 : 0.0295\n",
      "[2] valid loss : 0.20538309916527542, valid acc : 94.5661214305517, valid f1 : 0.0286\n",
      "Finished Training\n",
      "[3] train loss : 9.936728929460514e-06, train acc : 0.18713612420293874, train f1 : 0.0296\n",
      "[3] valid loss : 0.17523836410372814, valid acc : 94.87108400332687, valid f1 : 0.0281\n",
      "Finished Training\n",
      "[4] train loss : 3.5218213270127308e-06, train acc : 0.19406709176601053, train f1 : 0.0295\n",
      "[4] valid loss : 0.14825712947889083, valid acc : 95.81369559190463, valid f1 : 0.0287\n",
      "Finished Training\n",
      "[5] train loss : 8.838258509058505e-06, train acc : 0.18713612420293874, train f1 : 0.0297\n",
      "[5] valid loss : 0.43591691293741547, valid acc : 92.32048794011644, valid f1 : 0.0275\n",
      "Finished Training\n",
      "[6] train loss : 6.666773799679504e-08, train acc : 0.19406709176601053, train f1 : 0.0302\n",
      "[6] valid loss : 0.10142010433076759, valid acc : 97.33850845578043, valid f1 : 0.0298\n",
      "Finished Training\n",
      "[7] train loss : 4.0284120927935874e-07, train acc : 0.19406709176601053, train f1 : 0.0301\n",
      "[7] valid loss : 0.20170242637695368, valid acc : 94.98197948433601, valid f1 : 0.0286\n",
      "Finished Training\n",
      "[8] train loss : 6.610001435092272e-08, train acc : 0.19406709176601053, train f1 : 0.0298\n",
      "[8] valid loss : 0.1068495683111111, valid acc : 97.1721652342667, valid f1 : 0.0293\n",
      "Finished Training\n",
      "[9] train loss : 3.542658078004024e-07, train acc : 0.19406709176601053, train f1 : 0.0302\n",
      "[9] valid loss : 0.145217767928626, valid acc : 96.7285833102301, valid f1 : 0.0292\n",
      "Finished Training\n",
      "[10] train loss : 4.815289003090584e-07, train acc : 0.19406709176601053, train f1 : 0.0308\n",
      "[10] valid loss : 0.17285777383339612, valid acc : 95.50873301912947, valid f1 : 0.0291\n",
      "Finished Training\n",
      "[11] train loss : 8.300210652123496e-07, train acc : 0.19406709176601053, train f1 : 0.0307\n",
      "[11] valid loss : 0.2365524844009373, valid acc : 95.81369559190463, valid f1 : 0.0283\n",
      "Finished Training\n",
      "[12] train loss : 6.755812137271278e-06, train acc : 0.18713612420293874, train f1 : 0.0301\n",
      "[12] valid loss : 0.4017463060860691, valid acc : 90.13030219018574, valid f1 : 0.0261\n",
      "Finished Training\n",
      "[13] train loss : 5.299351073517755e-07, train acc : 0.19406709176601053, train f1 : 0.0300\n",
      "[13] valid loss : 0.16261555717364398, valid acc : 96.3127252564458, valid f1 : 0.0287\n",
      "Finished Training\n",
      "[14] train loss : 3.226999251637608e-05, train acc : 0.16634322151372333, train f1 : 0.0308\n",
      "[14] valid loss : 0.1036178485945715, valid acc : 97.50485167729416, valid f1 : 0.0297\n",
      "Finished Training\n",
      "[15] train loss : 4.1522817184613814e-08, train acc : 0.19406709176601053, train f1 : 0.0306\n",
      "[15] valid loss : 0.15883198187983172, valid acc : 96.25727751594123, valid f1 : 0.0289\n",
      "Finished Training\n",
      "[16] train loss : 6.463399131462211e-06, train acc : 0.18713612420293874, train f1 : 0.0306\n",
      "[16] valid loss : 0.32385141261506517, valid acc : 94.34433046853341, valid f1 : 0.0289\n",
      "Finished Training\n",
      "[17] train loss : 4.955797408001672e-07, train acc : 0.19406709176601053, train f1 : 0.0308\n",
      "[17] valid loss : 0.19344308042017283, valid acc : 95.39783753812033, valid f1 : 0.0289\n",
      "Finished Training\n",
      "[18] train loss : 1.0855048060420813e-07, train acc : 0.19406709176601053, train f1 : 0.0300\n",
      "[18] valid loss : 0.13517815598173338, valid acc : 96.95037427224841, valid f1 : 0.0293\n",
      "Finished Training\n",
      "[19] train loss : 5.0498794479381104e-08, train acc : 0.19406709176601053, train f1 : 0.0308\n",
      "[19] valid loss : 0.15072410893315383, valid acc : 96.5067923482118, valid f1 : 0.0294\n",
      "Finished Training\n",
      "[20] train loss : 1.1162612167936459e-07, train acc : 0.19406709176601053, train f1 : 0.0310\n",
      "[20] valid loss : 0.08967594822567718, valid acc : 98.03160521208761, valid f1 : 0.0301\n",
      "Finished Training\n",
      "[21] train loss : 1.0148707652035682e-08, train acc : 0.19406709176601053, train f1 : 0.0306\n",
      "[21] valid loss : 0.13374403691072295, valid acc : 97.1721652342667, valid f1 : 0.0294\n",
      "Finished Training\n",
      "[22] train loss : 2.2871381588629447e-05, train acc : 0.18713612420293874, train f1 : 0.0304\n",
      "[22] valid loss : 0.5326283210736168, valid acc : 91.21153313002495, valid f1 : 0.0260\n",
      "Finished Training\n",
      "[23] train loss : 2.531633569446967e-08, train acc : 0.19406709176601053, train f1 : 0.0306\n",
      "[23] valid loss : 0.11268636147789014, valid acc : 97.86526199057388, valid f1 : 0.0298\n",
      "Finished Training\n",
      "[24] train loss : 6.574130679837253e-07, train acc : 0.19406709176601053, train f1 : 0.0311\n",
      "[24] valid loss : 0.16449958213667212, valid acc : 95.95231494316607, valid f1 : 0.0288\n",
      "Finished Training\n",
      "[25] train loss : 7.728559126007895e-07, train acc : 0.19406709176601053, train f1 : 0.0309\n",
      "[25] valid loss : 0.11158567713793044, valid acc : 97.36623232603272, valid f1 : 0.0297\n",
      "Finished Training\n",
      "[26] train loss : 1.7447277969040442e-06, train acc : 0.18713612420293874, train f1 : 0.0309\n",
      "[26] valid loss : 0.1259459661088635, valid acc : 96.92265040199612, valid f1 : 0.0291\n",
      "Finished Training\n",
      "[27] train loss : 2.55127718951087e-09, train acc : 0.19406709176601053, train f1 : 0.0305\n",
      "[27] valid loss : 0.18952047478952486, valid acc : 96.81175492098697, valid f1 : 0.0295\n",
      "Finished Training\n",
      "[28] train loss : 4.1606303966545966e-06, train acc : 0.18713612420293874, train f1 : 0.0309\n",
      "[28] valid loss : 0.1564688662764902, valid acc : 97.56029941779873, valid f1 : 0.0298\n",
      "Finished Training\n",
      "[29] train loss : 1.6100597122203908e-06, train acc : 0.19406709176601053, train f1 : 0.0310\n",
      "[29] valid loss : 0.16004479282603, valid acc : 96.06321042417521, valid f1 : 0.0286\n",
      "Finished Training\n",
      "[30] train loss : 1.058690827449027e-06, train acc : 0.19406709176601053, train f1 : 0.0307\n",
      "[30] valid loss : 0.6678655143999677, valid acc : 90.29664541169947, valid f1 : 0.0265\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "test_dir = '/opt/ml/input/data/eval'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "import Test_Dataset\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "\n",
    "\n",
    "transform = Compose([\n",
    "            Resize(512, 384, p=1.0),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = Test_Dataset.TestDataset(image_paths, transform)\n",
    "\n",
    "loader = data.DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "all_predictions = [] # 예측 라벨값\n",
    "all_predictions_values = [] # 마지막 노드값\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        all_predictions_values.extend(pred.cpu().numpy())\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "        \n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission_final.csv'), index=False)\n",
    "print('test inference is done!')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}